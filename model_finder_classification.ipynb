{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ML libraries\n",
    "import pycaret\n",
    "import xgboost\n",
    "import numpy as np\n",
    "\n",
    "# Snowpark for Python\n",
    "from snowflake.snowpark.session import Session\n",
    "import snowflake.snowpark.types as T\n",
    "import snowflake.snowpark.functions as F\n",
    "import snowflake.snowpark as snowpark\n",
    "from snowflake.snowpark.functions import datediff, to_date, col, expr\n",
    "\n",
    "# Import Misc\n",
    "import json\n",
    "import pandas as pd\n",
    "from pycaret.classification import setup, compare_models, tune_model, plot_model, interpret_model, create_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Snowflake Session object\n",
    "connection_parameters = json.load(open(\"connection.json\"))\n",
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the correct table\n",
    "tableName = 'PURCHASE_ORDER_HISTORY'\n",
    "dataframe = session.table(tableName)\n",
    "\n",
    "# Calculation to find the lag between Planned Delivery from Actual Delivery\n",
    "dataframe = dataframe.withColumn(\"target_feature\",\n",
    "                                    datediff('day', \n",
    "                                            col(\"DELIVERY_DATE_ML\"), \n",
    "                                            col(\"FIRST_GR_POSTING_DATE_ML\")))\n",
    "\n",
    "\n",
    "# Example: Selecting specific columns\n",
    "# This selects only a subset of columns. Adjust the column names as needed.\n",
    "filtered_dataframe = dataframe.select(\n",
    "    col(\"PURCHASE_DOCUMENT_ITEM_ID\"), # ID for purchase order\n",
    "    col(\"CREATE_DATE_ML\"),            # day purchase order was created\n",
    "    col(\"COMPANY_CODE_ID\"),           # copmany w/in INVISTA making purchase\n",
    "    col(\"VENDOR_ID\"),                 # ID of the vendor \"we\" are purchasing from\n",
    "    col(\"POSTAL_CD\"),                 # postal code associated w company code ID\n",
    "    col(\"MATERIAL_ID\"),               # ID of material being purchase\n",
    "    col(\"SUB_COMMODITY_DESC\"),        # description of sub commodity\n",
    "    col(\"MRP_TYPE_ID\"),               # determined if material is reordered manually or automatically\n",
    "    col(\"PLANT_ID\"),                  # ID of plant making purchase\n",
    "    col(\"REQUESTED_DELIVERY_DATE_ML\"),# delivery date from requisition\n",
    "    col(\"INBOUND_DELIVERY_ID\"),       # ID for delivery\n",
    "    col(\"INBOUND_DELIVERY_ITEM_ID\"),  # ID of item w/in delivery\n",
    "    col(\"PLANNED_DELIVERY_DAYS\"),     # Amount of days expected to take\n",
    "    col(\"FIRST_GR_POSTING_DATE_ML\"),  # expected delivery date      \n",
    "    col(\"target_feature\")             # Lag between Planned Delivery from Actual Delivery \n",
    ")\n",
    "\n",
    "\n",
    "# Print a sample of the filtered dataframe to standard output.\n",
    "filtered_dataframe.show()\n",
    "\n",
    "# Optionally, you might want to filter rows based on some conditions\n",
    "# Example: Filtering out rows where FIRST_GR_POSTING_DATE_ML is NULL\n",
    "filtered_dataframe = filtered_dataframe.filter(col(\"FIRST_GR_POSTING_DATE_ML\").is_not_null())\n",
    "\n",
    "# Show the DataFrame after filtering\n",
    "filtered_dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'filtered_dataframe' is the DataFrame you've prepared in Snowflake\n",
    "# Convert the Snowpark DataFrame to a Pandas DataFrame with consideration for NULL values\n",
    "\n",
    "# Convert DataFrame to Pandas, handling NULL values by allowing float conversion\n",
    "df = filtered_dataframe.fillna(0).to_pandas()  # This replaces NULL with 0 before conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[(df['TARGET_FEATURE'] <= 100) & (df['TARGET_FEATURE'] >= -100)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins from -100 to 100, with each bin covering a 20-day range\n",
    "bins = list(range(-100, 101, 10))  # This creates bins at every 20 units from -100 to 100\n",
    "\n",
    "# Create labels for these bins\n",
    "labels = [f'{i} to {i+9}' for i in bins[:-1]]  # Exclude the last bin edge for labeling\n",
    "\n",
    "# Categorize the days into bins\n",
    "df_filtered['time_slot'] = pd.cut(df_filtered['TARGET_FEATURE'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.dropna(subset=['time_slot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['time_slot'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the original 'target_feature' column from the DataFrame\n",
    "df_filtered = df_filtered.drop(columns=['TARGET_FEATURE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the PyCaret environment for classification\n",
    "clf_setup = setup(data=df_filtered, target='time_slot', session_id=123, use_gpu=True, n_jobs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of model IDs you're interested in\n",
    "# 'rf' - Random Forest, 'et' - Extra Trees, 'dt' - Decision Tree\n",
    "model_ids = ['rf', 'et', 'dt']\n",
    "\n",
    "# Use compare_models but only for the specified models\n",
    "best_model = compare_models(include=model_ids, fold=5, round=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating models individually\n",
    "rf_model = create_model('rf')\n",
    "et_model = create_model('et')\n",
    "dt_model = create_model('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(rf_model, plot='confusion_matrix')\n",
    "plot_model(et_model, plot='confusion_matrix')\n",
    "plot_model(dt_model, plot='confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(rf_model, plot='confusion_matrix')\n",
    "plot_model(et_model, plot='confusion_matrix')\n",
    "plot_model(dt_model, plot='confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
